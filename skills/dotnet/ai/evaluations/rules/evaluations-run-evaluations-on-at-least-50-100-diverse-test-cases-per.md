---
title: "Run evaluations on at least 50-100 diverse test cases per..."
impact: MEDIUM
impactDescription: "general best practice"
tags: evaluations, dotnet, ai, evaluating-llm-response-quality, measuring-prompt-effectiveness, automated-ai-output-scoring
---

## Run evaluations on at least 50-100 diverse test cases per...

Run evaluations on at least 50-100 diverse test cases per prompt variation to get statistically meaningful quality scores rather than relying on a handful of examples.
