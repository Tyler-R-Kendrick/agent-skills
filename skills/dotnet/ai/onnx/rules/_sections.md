# ONNX Rules

Best practices and rules for ONNX.

## Rules

| # | Rule | Impact | File |
|---|------|--------|------|
| 1 | Optimize models before export | MEDIUM | [`onnx-optimize-models-before-export.md`](onnx-optimize-models-before-export.md) |
| 2 | Use appropriate execution providers (CPU/GPU) | MEDIUM | [`onnx-use-appropriate-execution-providers-cpu-gpu.md`](onnx-use-appropriate-execution-providers-cpu-gpu.md) |
| 3 | Batch inputs when possible | MEDIUM | [`onnx-batch-inputs-when-possible.md`](onnx-batch-inputs-when-possible.md) |
| 4 | Monitor inference performance | MEDIUM | [`onnx-monitor-inference-performance.md`](onnx-monitor-inference-performance.md) |
| 5 | Version your models | MEDIUM | [`onnx-version-your-models.md`](onnx-version-your-models.md) |
